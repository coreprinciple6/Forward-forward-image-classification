{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nimport random\nfrom tensorflow.compiler.tf2xla.python import xla","metadata":{"id":"MO8O0AiG9STy","execution":{"iopub.status.busy":"2023-04-13T16:57:14.144466Z","iopub.execute_input":"2023-04-13T16:57:14.145798Z","iopub.status.idle":"2023-04-13T16:57:14.153261Z","shell.execute_reply.started":"2023-04-13T16:57:14.145738Z","shell.execute_reply":"2023-04-13T16:57:14.151795Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset and visualize the data\n\nWe use the `keras.datasets.mnist.load_data()` utility to directly pull the MNIST dataset\nin the form of `NumPy` arrays. We then arrange it in the form of the train and test\nsplits.\n\nFollowing loading the dataset, we select 4 random samples from within the training set\nand visualize them using `matplotlib.pyplot`.","metadata":{"id":"8qH6C3LW9STz"}},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n\nprint(\"4 Random Training samples and labels\")\nidx1, idx2, idx3, idx4 = random.sample(range(0, x_train.shape[0]), 4)\n\nimg1 = (x_train[idx1], y_train[idx1])\nimg2 = (x_train[idx2], y_train[idx2])\nimg3 = (x_train[idx3], y_train[idx3])\nimg4 = (x_train[idx4], y_train[idx4])\n\nimgs = [img1, img2, img3, img4]\n\nplt.figure(figsize=(10, 10))\n\nfor idx, item in enumerate(imgs):\n    image, label = item[0], item[1]\n    plt.subplot(2, 2, idx + 1)\n    plt.imshow(image, cmap=\"gray\")\n    plt.title(f\"Label : {label}\")\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":624},"id":"_8EkzEhb9STz","outputId":"ec041009-3c68-4ad8-b903-d77fcf1521a0","execution":{"iopub.status.busy":"2023-04-13T16:57:14.183156Z","iopub.execute_input":"2023-04-13T16:57:14.183806Z","iopub.status.idle":"2023-04-13T16:57:15.239985Z","shell.execute_reply.started":"2023-04-13T16:57:14.183767Z","shell.execute_reply":"2023-04-13T16:57:15.238627Z"},"trusted":true},"execution_count":175,"outputs":[{"name":"stdout","text":"4 Random Training samples and labels\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x1000 with 4 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"\nclass FFDense(keras.layers.Layer):\n    \"\"\"\n    A custom ForwardForward-enabled Dense layer. It has an implementation of the\n    Forward-Forward network internally for use.\n    This layer must be used in conjunction with the `FFNetwork` model.\n    \"\"\"\n\n    def __init__(\n        self,\n        units,\n        optimizer,\n        loss_metric,\n        num_epochs=60,\n        use_bias=True,\n        kernel_initializer=\"glorot_uniform\",\n        bias_initializer=\"zeros\",\n        kernel_regularizer=None,\n        bias_regularizer=None,\n        **kwargs,\n    ):\n        super().__init__(**kwargs)\n        self.dense = keras.layers.Dense(\n            units=units,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n        )\n        self.relu = keras.layers.ReLU()\n        self.optimizer = optimizer\n        self.loss_metric = loss_metric\n        self.threshold = 1.5\n        self.num_epochs = num_epochs\n\n    # We perform a normalization step before we run the input through the Dense\n    # layer.\n\n    def call(self, x):\n        x_norm = tf.norm(x, ord=2, axis=1, keepdims=True)\n        x_norm = x_norm + 1e-4\n        x_dir = x / x_norm\n        res = self.dense(x_dir)\n        return self.relu(res)\n\n    # The Forward-Forward algorithm is below. We first perform the Dense-layer\n    # operation and then get a Mean Square value for all positive and negative\n    # samples respectively.\n    # The custom loss function finds the distance between the Mean-squared\n    # result and the threshold value we set (a hyperparameter) that will define\n    # whether the prediction is positive or negative in nature. Once the loss is\n    # calculated, we get a mean across the entire batch combined and perform a\n    # gradient calculation and optimization step. This does not technically\n    # qualify as backpropagation since there is no gradient being\n    # sent to any previous layer and is completely local in nature.\n\n    def forward_forward(self, x_pos, x_neg):\n        for i in range(self.num_epochs):\n            with tf.GradientTape() as tape:\n                g_pos = tf.math.reduce_mean(tf.math.pow(self.call(x_pos), 2), 1)\n                g_neg = tf.math.reduce_mean(tf.math.pow(self.call(x_neg), 2), 1)\n\n                loss = tf.math.log(\n                    1\n                    + tf.math.exp(\n                        tf.concat([-g_pos + self.threshold, g_neg - self.threshold], 0)\n                    )\n                )\n                mean_loss = tf.cast(tf.math.reduce_mean(loss), tf.float32)\n                self.loss_metric.update_state([mean_loss])\n            gradients = tape.gradient(mean_loss, self.dense.trainable_weights)\n            self.optimizer.apply_gradients(zip(gradients, self.dense.trainable_weights))\n        return (\n            tf.stop_gradient(self.call(x_pos)),\n            tf.stop_gradient(self.call(x_neg)),\n            self.loss_metric.result(),\n        )","metadata":{"id":"p9ZD0Qf-9ST0","execution":{"iopub.status.busy":"2023-04-13T16:57:15.242993Z","iopub.execute_input":"2023-04-13T16:57:15.243973Z","iopub.status.idle":"2023-04-13T16:57:15.260303Z","shell.execute_reply.started":"2023-04-13T16:57:15.243913Z","shell.execute_reply":"2023-04-13T16:57:15.258945Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"markdown","source":"## Define the `FFNetwork` Custom Model\n\nWith our custom layer defined, we also need to override the `train_step` method and\ndefine a custom `keras.models.Model` that works with our `FFDense` layer.\n\nFor this algorithm, we must 'embed' the labels onto the original image. To do so, we\nexploit the structure of MNIST images where the top-left 10 pixels are always zeros. We\nuse that as a label space in order to visually one-hot-encode the labels within the image\nitself. This action is performed by the `overlay_y_on_x` function.\n\nWe break down the prediction function with a per-sample prediction function which is then\ncalled over the entire test set by the overriden `predict()` function. The prediction is\nperformed here with the help of measuring the `excitation` of the neurons per layer for\neach image. This is then summed over all layers to calculate a network-wide 'goodness\nscore'. The label with the highest 'goodness score' is then chosen as the sample\nprediction.\n\nThe `train_step` function is overriden to act as the main controlling loop for running\ntraining on each layer as per the number of epochs per layer.","metadata":{"id":"wbwtEHx59ST1"}},{"cell_type":"markdown","source":"## Convert MNIST `NumPy` arrays to `tf.data.Dataset`\n\nWe now perform some preliminary processing on the `NumPy` arrays and then convert them\ninto the `tf.data.Dataset` format which allows for optimized loading.","metadata":{"id":"h-kpGNqx9ST2"}},{"cell_type":"code","source":"x_train = x_train.astype(float) / 255\nx_test = x_test.astype(float) / 255\ny_train = y_train.astype(int)\ny_test = y_test.astype(int)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\ntest_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n\ntrain_dataset = train_dataset.batch(60000)\ntest_dataset = test_dataset.batch(10000)","metadata":{"id":"qqht_XWA9ST2","execution":{"iopub.status.busy":"2023-04-13T16:57:15.262104Z","iopub.execute_input":"2023-04-13T16:57:15.262504Z","iopub.status.idle":"2023-04-13T16:57:16.443913Z","shell.execute_reply.started":"2023-04-13T16:57:15.262467Z","shell.execute_reply":"2023-04-13T16:57:16.442611Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"# find the dimensions of our images\nimg_width, img_height = x_train.shape[1], x_train.shape[2]\nprint(f\"Image dimensions are {img_width} x {img_height}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-13T16:57:16.446050Z","iopub.execute_input":"2023-04-13T16:57:16.446923Z","iopub.status.idle":"2023-04-13T16:57:16.457559Z","shell.execute_reply.started":"2023-04-13T16:57:16.446849Z","shell.execute_reply":"2023-04-13T16:57:16.455242Z"},"trusted":true},"execution_count":178,"outputs":[{"name":"stdout","text":"Image dimensions are 28 x 28\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Fit the network and visualize results\n\nHaving performed all previous set-up, we are now going to run `model.fit()` and run 250\nmodel epochs, which will perform 50*250 epochs on each layer. We get to see the plotted loss\ncurve as each layer is trained.","metadata":{"id":"0oatKqiQ9ST2"}},{"cell_type":"code","source":"def custom_loss(y_true, y_pred):\n    return K.mean(K.square(y_pred-y_true)/K.clip(K.square(0.01*y_pred), K.epsilon(), None), axis=-1)","metadata":{"id":"YMGoB0xMPGcl","execution":{"iopub.status.busy":"2023-04-13T16:57:16.461957Z","iopub.execute_input":"2023-04-13T16:57:16.462833Z","iopub.status.idle":"2023-04-13T16:57:16.476255Z","shell.execute_reply.started":"2023-04-13T16:57:16.462772Z","shell.execute_reply":"2023-04-13T16:57:16.474128Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"\nclass FFconv(keras.layers.Layer):\n    \"\"\"\n    A custom ForwardForward-enabled convolutional layer.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        num_filters,\n        optimizer,\n        loss_metric,\n        num_epochs=60,\n        use_bias=True,\n        kernel_initializer=\"glorot_uniform\",\n        bias_initializer=\"zeros\",\n        kernel_regularizer=None,\n        kernel_size=(3, 3),\n        bias_regularizer=None,\n        **kwargs,\n    ):\n        super().__init__(**kwargs)\n       \n        self.relu = keras.layers.ReLU()\n        self.optimizer = optimizer\n        self.loss_metric = loss_metric\n        self.threshold = 1.5\n        self.num_epochs = num_epochs\n\n        # we do the same for the convolutional layer\n\n        self.conv = keras.layers.Conv2D(\n            filters=num_filters,\n            kernel_size=kernel_size,\n            strides=(1, 1),\n            padding=\"same\",\n            activation=\"relu\",\n            kernel_initializer=\"he_normal\",\n            bias_initializer=\"zeros\",\n        )\n\n\n\n    # We perform a normalization step before we run the input through the Dense\n    # layer.\n\n    def call(self, x): # we adapt to use on the convolutional layer\n    \n        x = self.conv(x)\n        #print(x.shape)\n        x_norm = tf.norm(x, ord=2, axis=1, keepdims=True)\n        x_norm = x_norm + 1e-4\n        x_dir = x / x_norm\n        res = self.relu(x_dir)\n        #print(res.shape)\n        return res\n\n    # The Forward-Forward algorithm is below. We first perform the Dense-layer\n    # operation and then get a Mean Square value for all positive and negative\n    # samples respectively.\n    # The custom loss function finds the distance between the Mean-squared\n    # result and the threshold value we set (a hyperparameter) that will define\n    # whether the prediction is positive or negative in nature. Once the loss is\n    # calculated, we get a mean across the entire batch combined and perform a\n    # gradient calculation and optimization step. This does not technically\n    # qualify as backpropagation since there is no gradient being\n    # sent to any previous layer and is completely local in nature.\n\n    def forward_forward(self, x_pos, x_neg): # adapt to use on the convolutional layer, first the x_pos and x_neg need to be reshaped\n        # we flatten the input\n        #x_pos = tf.reshape(x_pos, [-1, tf.shape(x_pos)[1] * tf.shape(x_pos)[2]])\n        #x_neg = tf.reshape(x_neg, [-1, tf.shape(x_neg)[1] * tf.shape(x_neg)[2]])\n        for i in range(self.num_epochs):\n            with tf.GradientTape() as tape:\n                # g_pos must be calculated for each image, and is the sum of the squared values of the output of the x_pos vector\n                # g_neg must be calculated for each image, and is the sum of the squared values of the output of the x_neg vector\n                g_pos = tf.math.reduce_sum(tf.math.square(self.call(x_pos)), 1)\n                g_neg = tf.math.reduce_sum(tf.math.square(self.call(x_neg)), 1)\n                #print(\"g_pos\",g_pos)\n                loss = tf.math.log(\n                    1\n                    + tf.math.exp(\n                        tf.concat([-g_pos + self.threshold, g_neg - self.threshold], 0)\n                    )\n                )\n                mean_loss = tf.cast(tf.math.reduce_mean(loss), tf.float32)\n                self.loss_metric.update_state([mean_loss])\n            gradients = tape.gradient(mean_loss, self.dense.trainable_weights)\n            self.optimizer.apply_gradients(zip(gradients, self.dense.trainable_weights))\n        return (\n            tf.stop_gradient(self.call(x_pos)),\n            tf.stop_gradient(self.call(x_neg)),\n            self.loss_metric.result(),\n        )\n","metadata":{"execution":{"iopub.status.busy":"2023-04-13T16:57:16.479482Z","iopub.execute_input":"2023-04-13T16:57:16.480105Z","iopub.status.idle":"2023-04-13T16:57:16.500905Z","shell.execute_reply.started":"2023-04-13T16:57:16.480047Z","shell.execute_reply":"2023-04-13T16:57:16.499158Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"code","source":"class FFConvModel(keras.Model):\n    \"\"\"\n    A custom ForwardForward-enabled convolutional model.\n\n    \"\"\"\n\n    def __init__(self,dims,loss_metric,optimizer,layer_optimizer=keras.optimizers.legacy.Adam(learning_rate=0.03),num_filters=32,**kwargs):\n\n        super().__init__(**kwargs)\n        self.layer_optimizer = layer_optimizer\n        self.loss_var = tf.Variable(0.0, trainable=False, dtype=tf.float32)\n        self.loss_count = tf.Variable(0.0, trainable=False, dtype=tf.float32)\n        self.layer_list = []\n        self.layer_list.append(\n            FFconv(\n                num_filters=num_filters,\n                kernel_size=(3, 3),\n                optimizer=optimizer,\n                loss_metric=loss_metric,\n                num_epochs=60,\n                name=\"FFconv_1\",\n            )\n        )\n        # we add the flatten layer \n        self.layer_list.append(keras.layers.Flatten())\n        self.layer_list.append(FFDense(units=10, optimizer=optimizer, loss_metric=loss_metric, num_epochs=60, name=\"FFdense_1\"))\n\n\n    # This function makes a dynamic change to the image wherein the labels are\n    # put on top of the original image (for this example, as MNIST has 10\n    # unique labels, we take the top-left corner's first 10 pixels). This\n    # function returns the original data tensor with the first 10 pixels being\n    # a pixel-based one-hot representation of the labels.\n\n    @tf.function(reduce_retracing=True)\n    def overlay_y_on_x(self, data):\n        X_sample, y_sample = data\n        max_sample = tf.reduce_max(X_sample, axis=0, keepdims=True)\n        max_sample = tf.cast(max_sample, dtype=tf.float64)\n        X_zeros = tf.zeros([10], dtype=tf.float64)\n        X_update = xla.dynamic_update_slice(X_zeros, max_sample, [y_sample])\n        X_sample = xla.dynamic_update_slice(X_sample, X_update, [0])\n        return X_sample, y_sample\n\n    # A custom `predict_one_sample` performs predictions by passing the images\n    # through the network, measures the results produced by each layer (i.e.\n    # how high/low the output values are with respect to the set threshold for\n    # each label) and then simply finding the label with the highest values.\n    # In such a case, the images are tested for their 'goodness' with all\n    # labels.\n\n    @tf.function(reduce_retracing=True)\n    def predict_one_sample(self, x):\n        goodness_per_label = []\n        #x = tf.reshape(x, [tf.shape(x)[0] * tf.shape(x)[1]])\n        for label in range(10):\n            h, label = self.overlay_y_on_x(data=(x, label))\n            h = tf.reshape(h, [-1, tf.shape(h)[0]])\n            goodness = []\n            for layer_idx in range(1, len(self.layer_list)):\n                layer = self.layer_list[layer_idx]\n                h = layer(h)\n                \n                goodness += [tf.math.reduce_mean(tf.math.pow(h, 2), 1)]\n            goodness_per_label += [\n                tf.expand_dims(tf.reduce_sum(goodness, keepdims=True), 1)\n            ]\n        goodness_per_label = tf.concat(goodness_per_label, 1)\n        return tf.cast(tf.argmax(goodness_per_label, 1), tf.float64)\n\n    def predict(self, data):\n        x = data\n        preds = list()\n        preds = tf.map_fn(fn=self.predict_one_sample, elems=x)\n        return np.asarray(preds, dtype=int)\n\n    # This custom `train_step` function overrides the internal `train_step`\n    # implementation. We take all the input image tensors, flatten them and\n    # subsequently produce positive and negative samples on the images.\n    # A positive sample is an image that has the right label encoded on it with\n    # the `overlay_y_on_x` function. A negative sample is an image that has an\n    # erroneous label present on it.\n    # With the samples ready, we pass them through each `FFLayer` and perform\n    # the Forward-Forward computation on it. The returned loss is the final\n    # loss value over all the layers.\n\n    @tf.function(jit_compile=True)\n    def train_step(self, data):\n        x, y = data\n        # we store the shape of the input tensor to reshape the output\n        input_shape = tf.shape(x)\n\n        # Flatten op\n        x = tf.reshape(x, [-1, tf.shape(x)[1] * tf.shape(x)[2]])\n        # convert to float64\n        x = tf.cast(x, dtype=tf.float64)\n        x_pos, y = tf.map_fn(fn=self.overlay_y_on_x, elems=(x, y))\n        random_y = tf.random.shuffle(y)\n        x_neg, y = tf.map_fn(fn=self.overlay_y_on_x, elems=(x, random_y))\n        \n        h_pos, h_neg = x_pos, x_neg\n\n        for idx, layer in enumerate(self.layer_list):\n            if isinstance(layer, FFDense):\n                print(f\"Training layer {idx+1} now : \")\n                \n                h_pos, h_neg, loss = layer.forward_forward(h_pos, h_neg)\n                self.loss_var.assign_add(loss)\n                self.loss_count.assign_add(1.0)\n            if isinstance(layer, FFconv):\n                print(f\"Training layer {idx+1} now : \")\n                h_neg = tf.reshape(h_neg, [input_shape[0],input_shape[1],input_shape[2],1])\n                h_pos = tf.reshape(h_pos, [input_shape[0],input_shape[1],input_shape[2],1])\n                h_pos, h_neg, loss = layer.forward_forward(h_pos, h_neg)\n                self.loss_var.assign_add(loss)\n                self.loss_count.assign_add(1.0)\n            else:\n                print(f\"Passing layer {idx+1} now : \")\n                x = layer(x)\n        mean_res = tf.math.divide(self.loss_var, self.loss_count)\n        return {\"FinalLoss\": mean_res}\n    \n    \n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-13T16:57:16.503054Z","iopub.execute_input":"2023-04-13T16:57:16.503852Z","iopub.status.idle":"2023-04-13T16:57:16.544486Z","shell.execute_reply.started":"2023-04-13T16:57:16.503808Z","shell.execute_reply":"2023-04-13T16:57:16.542559Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"code","source":"# create the model\n\nloss_metric = keras.metrics.Mean(name=\"loss\")\noptimizer = keras.optimizers.Adam(learning_rate=0.001)\n\nmodel = FFConvModel(dims=[784],loss_metric=loss_metric,optimizer=optimizer)\n\n# compile the model\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-04-13T16:57:16.547405Z","iopub.execute_input":"2023-04-13T16:57:16.547984Z","iopub.status.idle":"2023-04-13T16:57:16.586845Z","shell.execute_reply.started":"2023-04-13T16:57:16.547914Z","shell.execute_reply":"2023-04-13T16:57:16.585644Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T16:57:16.588380Z","iopub.execute_input":"2023-04-13T16:57:16.588998Z","iopub.status.idle":"2023-04-13T16:57:16.594436Z","shell.execute_reply.started":"2023-04-13T16:57:16.588957Z","shell.execute_reply":"2023-04-13T16:57:16.593450Z"},"trusted":true},"execution_count":183,"outputs":[{"name":"stdout","text":"(60000, 28, 28)\n","output_type":"stream"}]},{"cell_type":"code","source":"# train the model\nmodel.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T16:57:16.595866Z","iopub.execute_input":"2023-04-13T16:57:16.596472Z","iopub.status.idle":"2023-04-13T16:57:17.156556Z","shell.execute_reply.started":"2023-04-13T16:57:16.596434Z","shell.execute_reply":"2023-04-13T16:57:17.154509Z"},"trusted":true},"execution_count":184,"outputs":[{"name":"stdout","text":"Epoch 1/10\nTraining layer 1 now : \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/26878198.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/__autograph_generated_filekqdkb2ob.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'idx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'h_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_pos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'(idx, layer)'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0mmean_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/__autograph_generated_filekqdkb2ob.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     67\u001b[0m                         \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Passing layer {(ag__.ld(idx) + 1)} now : '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFFconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'h_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_pos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'idx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/__autograph_generated_filekqdkb2ob.py\u001b[0m in \u001b[0;36mif_body_1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m                         \u001b[0mh_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                         \u001b[0mh_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mh_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                         \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                         \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/__autograph_generated_fileofj1uyz4.py\u001b[0m in \u001b[0;36mtf__forward_forward\u001b[0;34m(self, x_pos, x_neg)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gradients'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'i'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/__autograph_generated_fileofj1uyz4.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     23\u001b[0m                         \u001b[0mmean_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mg_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'g_neg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_27/2080321620.py\", line 114, in train_step  *\n        h_pos, h_neg, loss = layer.forward_forward(h_pos, h_neg)\n    File \"/tmp/ipykernel_27/1949813855.py\", line 87, in forward_forward  *\n        gradients = tape.gradient(mean_loss, self.dense.trainable_weights)\n\n    AttributeError: 'FFconv' object has no attribute 'dense'\n"],"ename":"AttributeError","evalue":"in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_27/2080321620.py\", line 114, in train_step  *\n        h_pos, h_neg, loss = layer.forward_forward(h_pos, h_neg)\n    File \"/tmp/ipykernel_27/1949813855.py\", line 87, in forward_forward  *\n        gradients = tape.gradient(mean_loss, self.dense.trainable_weights)\n\n    AttributeError: 'FFconv' object has no attribute 'dense'\n","output_type":"error"}]}]}